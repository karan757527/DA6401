{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe1c6e9-1751-4085-a2f3-ef368d8c413c",
   "metadata": {},
   "source": [
    "# DA6401 Assignment 1  \n",
    " \n",
    "- [GitHub Repository](https://github.com/karan757527/DA6401)  \n",
    "- [Project Report](https://wandb.ai/cs24m021-iit-madras/DA6401_DL_Assignment1/reports/DA6401-Assignment-1--VmlldzoxMTc4Mzg1Mw)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774dd86-4004-48ff-968d-6eeec441e1c2",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee20018-8afb-4cf5-9a88-2622625cf598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: wandb in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.19.7)\n",
      "Collecting argparse (from -r requirements.txt (line 7))\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from keras->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (3.1.37)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in /opt/anaconda3/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 6)) (1.3.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.41.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 6)) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 6)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras->-r requirements.txt (line 4)) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 5)) (2.1.3)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f5911a-48bf-43ab-aac4-bd8ffa36bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8ecbbe-b398-4744-a262-4f34061fc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/karanagrawal/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m021\u001b[0m (\u001b[33mcs24m021-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"843913992a9025996973825be4ad46e4636d0610\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e52d64-a568-4e04-8769-4e9646eec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"DA6401_Assignment1\" #\"DA6401_DL_Assignment1\"\n",
    "ENTITY = \"karan\"\n",
    "SWEEPCOUNT = 5 #250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf992f-ce80-4d1f-acc4-dce004734f6c",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f201fa9-7bab-447a-87ed-381b94bb22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question 1-8\n",
    "(train_img, train_labels), (test_img, test_labels) = fashion_mnist.load_data()\n",
    "target_classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "# for question 10\n",
    "(mnist_train, mnist_train_label), (mnist_test, mnist_test_label) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9182d6-4795-420e-9030-e7042756e3c2",
   "metadata": {},
   "source": [
    "## Question 1: Plot one sample per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3db74c-9b57-4973-a572-dd17c379050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/karanagrawal/Desktop/Sem 2/DL/Assignment 1/wandb/run-20250315_235335-q7euri80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1/runs/q7euri80' target=\"_blank\">Question_1</a></strong> to <a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1' target=\"_blank\">https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1/runs/q7euri80' target=\"_blank\">https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1/runs/q7euri80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Question_1</strong> at: <a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1/runs/q7euri80' target=\"_blank\">https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1/runs/q7euri80</a><br> View project at: <a href='https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1' target=\"_blank\">https://wandb.ai/cs24m021-iit-madras/DA6401_Assignment1</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250315_235335-q7euri80/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT, name=\"Question_1\")  \n",
    "sample = []\n",
    "for id in range(10):\n",
    "    index = np.where(train_labels == id)[0][0]  # first occurrence of each class\n",
    "    sample.append(train_img[index])  # corresponding image to the sample list\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 15))  \n",
    "fig.suptitle(\"Fashion-MNIST Sample Images\", fontsize=14)  \n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(sample):\n",
    "        ax.imshow(sample[i], cmap='gray')  # display the image in grayscale\n",
    "        ax.set_title(target_classes[i]) \n",
    "        ax.axis(\"off\") \n",
    "    else:\n",
    "        ax.axis(\"off\")  \n",
    "\n",
    "plt.tight_layout() \n",
    "wandb.log({\"Sample_Images\": wandb.Image(plt)})  # logging to wandb\n",
    "plt.show()\n",
    "wandb.finish(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfbe1b-6164-4ecf-af16-5a763cd66d20",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f58b1df-45b4-43ce-9299-5d6aaded0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Functions:\n",
    "    def __init__(self):\n",
    "        self.activation_functions = {\n",
    "            \"tanh\": self.tanh,\n",
    "            \"sigmoid\": self.sigmoid,\n",
    "            \"ReLU\": self.ReLU,\n",
    "            \"softmax\": self.softmax,\n",
    "            \"identity\": self.identity\n",
    "        }\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # numerical stability\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)  # softmax probabilities\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        result = np.zeros_like(x)\n",
    "        result[x >= 0] = 1 / (1 + np.exp(-x[x >= 0]))  # for positive values\n",
    "        result[x < 0] = np.exp(x[x < 0]) / (1 + np.exp(x[x < 0]))  # for negative values\n",
    "        return result\n",
    "\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)  # ReLU activation\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)  # hyperbolic tangent activation\n",
    "\n",
    "    def identity(self, x):\n",
    "        return x  # identity function\n",
    "\n",
    "    def activation(self, x, fun):\n",
    "        activation_function = self.activation_functions.get(fun)\n",
    "        if activation_function:\n",
    "            return activation_function(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{fun}' is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae421e1-7a19-43ba-8ea0-faaccb4c7f53",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58f861d-871c-4ec4-b5c1-9164ed4d5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_Function:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred, loss_function=\"cross_entropy\"):\n",
    "        if loss_function == \"cross_entropy\":\n",
    "            epsilon = 1e-15\n",
    "            y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip to avoid log(0)\n",
    "            return np.mean(-np.sum(y_true * np.log(y_pred), axis=1))  # cross-entropy loss\n",
    "        if loss_function == \"mean_squared_error\":\n",
    "            return 0.5 * np.mean(np.sum((y_true - y_pred) ** 2, axis=1))  # MSE loss\n",
    "\n",
    "    def last_output_derivative(self, y_pred, y_true, activation_derivative, loss_function=\"cross_entropy\"):\n",
    "        if loss_function == \"mean_squared_error\":\n",
    "            return (y_pred - y_true) * activation_derivative / len(y_true)  # MSE derivative\n",
    "        if loss_function == \"cross_entropy\":\n",
    "            return -(y_true - y_pred)  # cross-entropy derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66112254-bc9d-49cf-af7f-361303de2ecf",
   "metadata": {},
   "source": [
    "### Derivatioves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399cb629-a646-4080-bc30-11dd8c58dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Derivatives:\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Functions()\n",
    "        self.derivative_functions = {\n",
    "            \"sigmoid\": self.sigmoid_derivative,\n",
    "            \"tanh\": self.tanh_derivative,\n",
    "            \"ReLU\": self.ReLU_derivative,\n",
    "            \"softmax\": self.softmax_derivative,\n",
    "            \"identity\": self.identity_derivative\n",
    "        }\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        k = self.activation.sigmoid(x)\n",
    "        return k * (1 - k)  # derivative of sigmoid\n",
    "\n",
    "    def softmax_derivative(self, x):\n",
    "        k = self.activation.softmax(x)\n",
    "        return k * (1 - k)  # derivative of softmax\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        k = self.activation.tanh(x)\n",
    "        return 1 - k ** 2  # derivative of tanh\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        x[x > 0] = 1  # derivative is 1 for x > 0\n",
    "        x[x <= 0] = 0  # derivative is 0 for x <= 0\n",
    "        return x\n",
    "\n",
    "    def identity_derivative(self, x):\n",
    "        return np.ones_like(x)  # derivative of identity is 1\n",
    "\n",
    "    def derivatives(self, x, activation_function):\n",
    "        derivative_function = self.derivative_functions.get(activation_function)\n",
    "        if derivative_function:\n",
    "            return derivative_function(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Derivative for activation function '{activation_function}' is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403bafe9-8b02-4040-8ae0-2b55ae08a1cf",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373fc4d0-57f4-4196-a0b3-38c0b2e1386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, weights, biases, activation, layer_sizes):\n",
    "    activation_func = Activation_Functions()\n",
    "    outputs, activations = {}, {}\n",
    "    outputs[0] = x  # input layer\n",
    "    \n",
    "    num_layers = len(layer_sizes)\n",
    "    \n",
    "    for layer in range(1, num_layers - 1):\n",
    "        activations[layer] = np.dot(outputs[layer - 1], weights[layer]) + biases[layer]  # linear transformation\n",
    "        outputs[layer] = activation_func.activation(activations[layer], fun=activation)  # apply activation\n",
    "    \n",
    "    activations[num_layers - 1] = np.dot(outputs[num_layers - 2], weights[num_layers - 1]) + biases[num_layers - 1]\n",
    "    outputs[num_layers - 1] = activation_func.activation(activations[num_layers - 1], fun=\"softmax\")  # softmax for output layer\n",
    "    \n",
    "    return outputs[num_layers - 1]  # final output\n",
    "\n",
    "def Network_Q2(data, activation, input_size, layers, output_size):\n",
    "    weights, biases = {}, {}\n",
    "    layer_sizes = [input_size] + layers + [output_size]  # define layer sizes\n",
    "    predicted_probs = []\n",
    "    \n",
    "    for layer in range(1, len(layer_sizes)):\n",
    "        weights[layer] = np.random.randn(layer_sizes[layer - 1], layer_sizes[layer])  # initialize weights\n",
    "        biases[layer] = np.random.randn(1, layer_sizes[layer])  # initialize biases\n",
    "    \n",
    "    for sample in data:\n",
    "        x = sample.reshape(1, -1) / 255.0  # normalize input\n",
    "        y_pred = forward_pass(x, weights, biases, activation, layer_sizes)  # forward pass\n",
    "        predicted_probs.append(y_pred)  # store predictions\n",
    "    \n",
    "    return predicted_probs  # return all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0288c9d3-9f39-49c1-9905-99c17bac9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.36000e-03 2.97000e-04 9.99060e-02 8.88156e-01 1.20000e-05\n",
      "   3.34200e-03 2.48800e-03 1.16000e-03 4.00000e-06 3.27400e-03]]\n",
      "\n",
      " [[7.13700e-03 1.90270e-02 5.77940e-01 1.91462e-01 1.51000e-04\n",
      "   3.47710e-02 1.05657e-01 5.89650e-02 2.67000e-04 4.62400e-03]]\n",
      "\n",
      " [[3.51600e-03 3.82000e-04 4.63640e-01 5.17520e-01 1.00000e-05\n",
      "   2.34500e-03 9.44200e-03 2.65800e-03 2.50000e-05 4.62000e-04]]\n",
      "\n",
      " [[3.38050e-02 1.00830e-02 5.53862e-01 3.11355e-01 8.60000e-05\n",
      "   2.42060e-02 3.72010e-02 2.50880e-02 2.86000e-04 4.02700e-03]]\n",
      "\n",
      " [[4.67780e-02 1.59100e-03 3.85896e-01 4.96653e-01 2.60000e-05\n",
      "   1.28030e-02 3.74600e-02 1.61560e-02 1.37000e-04 2.50000e-03]]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_Q2 = Network_Q2(train_img, \"sigmoid\", 784, [32, 32, 32], 10)  \n",
    "print(np.array(y_pred_Q2[:5]).round(6))  # print first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa887bba-57d6-4436-bf27-3fef1fdd3de1",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5550fbe8-0bba-4929-b620-13a594048ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, model, config):\n",
    "        self.model = model  \n",
    "        self.learning_rate = config[\"eta\"]  \n",
    "        self.decay = config[\"weight_decay\"]  \n",
    "        self.optim_type = config[\"optimizer\"]  \n",
    "        self.momentum = config[\"momentum\"] \n",
    "        self.beta1 = config[\"beta1\"] \n",
    "        self.beta2 = config[\"beta2\"]  \n",
    "        self.epsilon_val = config[\"epsilon\"]\n",
    "        self.optimization_methods = {\n",
    "            \"sgd\": self.stochastic_gradient_descent,\n",
    "            \"momentum\": self.momentum_gradient_descent,\n",
    "            \"nesterov\": self.nesterov_gradient_descent,\n",
    "            \"nag\": self.nesterov_gradient_descent,\n",
    "            \"rmsprop\": self.rmsprop,\n",
    "            \"adam\": self.adam,\n",
    "            \"nadam\": self.nadam\n",
    "        }\n",
    "\n",
    "    def update_parameters(self, timestep):\n",
    "        optimization_function = self.optimization_methods.get(self.optim_type)\n",
    "        \n",
    "        if optimization_function:\n",
    "            if self.optim_type in [\"adam\", \"nadam\"]:\n",
    "                optimization_function(timestep)\n",
    "            else:\n",
    "                optimization_function()\n",
    "        else:\n",
    "            raise ValueError(f\"Optimization method '{self.optim_type}' is not supported.\")\n",
    "\n",
    "    def stochastic_gradient_descent(self):\n",
    "        param_layers = self.model.weights.keys()\n",
    "        for l in param_layers:\n",
    "            reg_term = self.model.weights[l] * self.decay  # weight decay\n",
    "            self.model.grad_weights[l] += reg_term\n",
    "            bias_update = self.learning_rate * self.model.grad_biases[l]  # bias update\n",
    "            self.model.biases[l] -= bias_update\n",
    "            weight_update = self.learning_rate * self.model.grad_weights[l]  # weight update\n",
    "            self.model.weights[l] -= weight_update\n",
    "\n",
    "    def momentum_gradient_descent(self):\n",
    "        for layer in self.model.weights.keys():\n",
    "            self.model.grad_weights[layer] += self.decay * self.model.weights[layer]  # weight decay\n",
    "            prev_momentum_w = self.momentum * self.model.m_weights[layer]\n",
    "            new_momentum_w = prev_momentum_w + self.learning_rate * self.model.grad_weights[layer]  # momentum update\n",
    "            prev_momentum_b = self.momentum * self.model.m_biases[layer]\n",
    "            new_momentum_b = prev_momentum_b + self.learning_rate * self.model.grad_biases[layer]\n",
    "            self.model.m_weights[layer] = new_momentum_w\n",
    "            self.model.m_biases[layer] = new_momentum_b\n",
    "            self.model.weights[layer] -= new_momentum_w\n",
    "            self.model.biases[layer] -= new_momentum_b\n",
    "\n",
    "    def nesterov_gradient_descent(self):\n",
    "        for l in self.model.weights.keys():\n",
    "            momentum_w = self.momentum * self.model.m_weights[l]  # momentum term\n",
    "            lookahead_w = self.model.weights[l] - momentum_w  # lookahead step\n",
    "            lookahead_b = self.model.biases[l] - self.momentum * self.model.m_biases[l]\n",
    "            self.model.grad_weights[l] += lookahead_w * self.decay  # weight decay\n",
    "            grad_w = self.model.grad_weights[l]\n",
    "            grad_b = self.model.grad_biases[l]\n",
    "            new_m_w = self.momentum * self.model.m_weights[l] - self.learning_rate * grad_w  # update momentum\n",
    "            new_m_b = self.momentum * self.model.m_biases[l] - self.learning_rate * grad_b\n",
    "            self.model.weights[l] += new_m_w\n",
    "            self.model.biases[l] += new_m_b\n",
    "            self.model.m_weights[l] = new_m_w\n",
    "            self.model.m_biases[l] = new_m_b\n",
    "\n",
    "    def rmsprop(self):\n",
    "        for layer in self.model.weights.keys():\n",
    "            current_grad_w = self.model.grad_weights[layer] + self.model.weights[layer] * self.decay  # weight decay\n",
    "            current_grad_b = self.model.grad_biases[layer]\n",
    "            self.model.v_weights[layer] = self.beta2*self.model.v_weights[layer] + (1-self.beta2)*(current_grad_w**2)  # velocity update\n",
    "            self.model.v_biases[layer] = self.beta2*self.model.v_biases[layer] + (1-self.beta2)*(current_grad_b**2)\n",
    "            epsilon = 1e-8 if self.epsilon_val < 1e-8 else self.epsilon_val  # numerical stability\n",
    "            self.model.weights[layer] -= (current_grad_w * self.learning_rate) / (np.sqrt(self.model.v_weights[layer]) + epsilon)  # update weights\n",
    "            self.model.biases[layer] -= (current_grad_b * self.learning_rate) / (np.sqrt(self.model.v_biases[layer]) + epsilon)\n",
    "\n",
    "    def adam(self, step):\n",
    "        for l in self.model.weights.keys():\n",
    "            decay_contribution = self.decay * self.model.weights[l] # weight decay\n",
    "            self.model.grad_weights[l] += decay_contribution\n",
    "            \n",
    "            grad_w = np.clip(self.model.grad_weights[l], -1e3, 1e3)\n",
    "            grad_b = np.clip(self.model.grad_biases[l], -1e3, 1e3)\n",
    "            \n",
    "            m_w = self.beta1 * self.model.m_weights[l] + (1 - self.beta1) * grad_w # momentum update with numerical stability\n",
    "            m_b = self.beta1 * self.model.m_biases[l] + (1 - self.beta1) * grad_b\n",
    "            \n",
    "            v_w = self.beta2 * self.model.v_weights[l] + (1 - self.beta2) * (grad_w**2 + 1e-8)\n",
    "            v_b = self.beta2 * self.model.v_biases[l] + (1 - self.beta2) * (grad_b**2 + 1e-8)\n",
    "            \n",
    "            self.model.m_weights[l], self.model.v_weights[l] = m_w, v_w\n",
    "            self.model.m_biases[l], self.model.v_biases[l] = m_b, v_b\n",
    "            \n",
    "            beta1_t = max(self.beta1**step, 1e-8)\n",
    "            beta2_t = max(self.beta2**step, 1e-8)\n",
    "            mw_corrected = m_w / (1 - beta1_t + 1e-8)\n",
    "            vw_corrected = v_w / (1 - beta2_t + 1e-8)\n",
    "            mb_corrected = m_b / (1 - beta1_t + 1e-8)\n",
    "            vb_corrected = v_b / (1 - beta2_t + 1e-8)\n",
    "            \n",
    "            weight_update = self.learning_rate * mw_corrected / (np.sqrt(vw_corrected) + self.epsilon_val)\n",
    "            bias_update = self.learning_rate * mb_corrected / (np.sqrt(vb_corrected) + self.epsilon_val)\n",
    "            \n",
    "            self.model.weights[l] -= np.clip(weight_update, -1e3, 1e3)\n",
    "            self.model.biases[l] -= np.clip(bias_update, -1e3, 1e3)\n",
    "\n",
    "    def nadam(self, step):\n",
    "        for l in self.model.weights.keys():\n",
    "            self.model.grad_weights[l] += self.model.weights[l] * self.decay\n",
    "            grad_w = np.clip(self.model.grad_weights[l], -1e3, 1e3)\n",
    "            grad_b = np.clip(self.model.grad_biases[l], -1e3, 1e3)\n",
    "            \n",
    "            m_w_new = self.beta1 * self.model.m_weights[l] + (1-self.beta1)*grad_w\n",
    "            m_b_new = self.beta1 * self.model.m_biases[l] + (1-self.beta1)*grad_b\n",
    "\n",
    "            v_w_new = self.beta2 * self.model.v_weights[l] + (1-self.beta2)*(grad_w**2 + 1e-8)\n",
    "            v_b_new = self.beta2 * self.model.v_biases[l] + (1-self.beta2)*(grad_b**2 + 1e-8)\n",
    "            \n",
    "            beta1_t = max(self.beta1**step, 1e-8)\n",
    "            beta2_t = max(self.beta2**step, 1e-8)\n",
    "            mw_hat = m_w_new / (1 - beta1_t + 1e-8)\n",
    "            vw_hat = v_w_new / (1 - beta2_t + 1e-8)\n",
    "            mb_hat = m_b_new / (1 - beta1_t + 1e-8)\n",
    "            vb_hat = v_b_new / (1 - beta2_t + 1e-8)\n",
    "            \n",
    "            nesterov_w = self.beta1 * mw_hat + (1-self.beta1)*grad_w/(1 - beta1_t + 1e-8)\n",
    "            nesterov_b = self.beta1 * mb_hat + (1-self.beta1)*grad_b/(1 - beta1_t + 1e-8)\n",
    "            \n",
    "            weight_update = self.learning_rate * nesterov_w / (np.sqrt(vw_hat) + self.epsilon_val)\n",
    "            bias_update = self.learning_rate * nesterov_b / (np.sqrt(vb_hat) + self.epsilon_val)\n",
    "            \n",
    "            self.model.weights[l] -= np.clip(weight_update, -1e3, 1e3)\n",
    "            self.model.biases[l] -= np.clip(bias_update, -1e3, 1e3)\n",
    "            \n",
    "            self.model.m_weights[l], self.model.v_weights[l] = m_w_new, v_w_new\n",
    "            self.model.m_biases[l], self.model.v_biases[l] = m_b_new, v_b_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b19a0e-8173-4b38-81bc-8ac2f639f0dd",
   "metadata": {},
   "source": [
    "### Final Neural Network Functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568cab05-630a-41fe-bbbb-6e008e495dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, config, log=1, console=1):\n",
    "        self.weights, self.biases, self.a, self.h = {}, {}, {}, {}\n",
    "        self.grad_weights, self.grad_biases, self.m_weights, self.m_biases = {}, {}, {}, {}\n",
    "        self.v_weights, self.v_biases = {}, {}\n",
    "\n",
    "        self.activation_function = config[\"activation_function\"]\n",
    "        self.loss_function = config[\"loss_function\"]\n",
    "        self.initialization = config[\"init\"]\n",
    "        self.hidden_layers = config[\"hidden_layers\"]\n",
    "        self.hidden_layer_sizes = config[\"hidden_layer_sizes\"]\n",
    "        self.dataset = config[\"dataset\"]\n",
    "        self.wan_log, self.console_log = log, console\n",
    "        self.loss = Loss_Function()\n",
    "        self.act = Activation_Functions()\n",
    "        self.derivative = Derivatives()\n",
    "\n",
    "        (train_img, train_lbl), (test_img, test_lbl) = self.load_dataset()\n",
    "        train_img, val_img, train_lbl, val_lbl = train_test_split(train_img, train_lbl, test_size=0.1, random_state=41)\n",
    "\n",
    "        self.input, self.y_true = self.preprocess_data(train_img, train_lbl)  # preprocess training data\n",
    "        self.val_img, self.val_true = self.preprocess_data(val_img, val_lbl)  # preprocess validation data\n",
    "        self.test_img, self.test_true = self.preprocess_data(test_img, test_lbl)  # preprocess test data\n",
    "        self.layers = [self.input.shape[1]] + [self.hidden_layer_sizes] * self.hidden_layers + [10]  \n",
    "        \n",
    "        self.initialize_parameters()  # initialize weights and biases\n",
    "\n",
    "    def load_dataset(self):\n",
    "        if self.dataset == 'fashion_mnist':\n",
    "            return (train_img, train_labels), (test_img, test_labels)\n",
    "        if self.dataset == 'mnist':\n",
    "            return (mnist_train, mnist_train_label), (mnist_test, mnist_test_label)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown dataset\")\n",
    "\n",
    "    def preprocess_data(self, images, labels):\n",
    "        return images.reshape(images.shape[0], -1) / 255.0 , labels  # normalize and reshape data\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        for layer in range(1, len(self.layers)):\n",
    "            self.v_weights[layer] = np.zeros((self.layers[layer-1], self.layers[layer]))  # initialize velocity for weights\n",
    "            self.v_biases[layer] = np.zeros((1, self.layers[layer]))  # initialize velocity for biases\n",
    "            \n",
    "            self.m_weights[layer] = np.zeros((self.layers[layer-1], self.layers[layer]))  # initialize momentum for weights\n",
    "            self.m_biases[layer] = np.zeros((1, self.layers[layer]))  # initialize momentum for biases\n",
    "            \n",
    "            if self.initialization == \"random\":\n",
    "                self.weights[layer] = np.random.normal(0, 1, (self.layers[layer-1], self.layers[layer]))\n",
    "                self.biases[layer] = np.random.normal(0, 1, (1, self.layers[layer]))\n",
    "            elif self.initialization == \"Xavier\":\n",
    "                scale_w = np.sqrt(2.0 / (self.layers[layer-1] + self.layers[layer]))\n",
    "                scale_b = np.sqrt(2.0 / (1 + self.layers[layer]))\n",
    "                self.weights[layer] = np.random.normal(0, scale_w, (self.layers[layer-1], self.layers[layer]))\n",
    "                self.biases[layer] = np.random.normal(0, scale_b, (1, self.layers[layer]))\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        self.h[0] = x\n",
    "        num_layers = len(self.layers) - 1\n",
    "    \n",
    "        for layer in range(1, num_layers):\n",
    "            linear_output = self.h[layer-1] @ self.weights[layer]\n",
    "            self.a[layer] = linear_output + self.biases[layer]   # linear transformation\n",
    "            self.h[layer] = self.act.activation(self.a[layer], self.activation_function)\n",
    "    \n",
    "        final_linear_output = self.h[num_layers-1] @ self.weights[num_layers]\n",
    "        self.a[num_layers] = final_linear_output + self.biases[num_layers]\n",
    "        self.h[num_layers] = self.act.activation(self.a[num_layers], \"softmax\") # softmax for output layer\n",
    "    \n",
    "        output = self.h[num_layers]\n",
    "        return output\n",
    "\n",
    "    def backward_propagation(self, x, y_true, y_hat): \n",
    "        output_layer_index = len(self.layers) - 1  # softmax derivative for output layer  \n",
    "        softmax_grad = self.derivative.derivatives(self.a[output_layer_index], \"softmax\")  \n",
    "        error = self.loss.last_output_derivative(y_hat, y_true, softmax_grad, self.loss_function)  \n",
    "    \n",
    "        # for hidden layers\n",
    "        for current_layer in reversed(range(2, len(self.layers))):  \n",
    "            prev_hidden = self.h[current_layer - 1]  \n",
    "    \n",
    "            self.grad_weights[current_layer] = prev_hidden.T @ error  \n",
    "            self.grad_biases[current_layer] = np.sum(error, axis=0, keepdims=True)  \n",
    "    \n",
    "            weight_matrix = self.weights[current_layer].T  \n",
    "            error_hidden = error @ weight_matrix  \n",
    "            deriv_activation = self.derivative.derivatives(self.a[current_layer - 1], self.activation_function)  \n",
    "            error = error_hidden * deriv_activation  \n",
    "    \n",
    "        input_grad_weights = x.T @ error  \n",
    "        input_grad_biases = np.sum(error, axis=0, keepdims=True)  \n",
    "        self.grad_weights[1] = input_grad_weights  \n",
    "        self.grad_biases[1] = input_grad_biases  \n",
    "\n",
    "    def one_hot_matrix(self, labels):\n",
    "        mat = np.zeros((labels.shape[0], 10)) \n",
    "        mat[np.arange(labels.shape[0]), labels] = 1\n",
    "        return mat\n",
    "\n",
    "    def compute_performance(self, data, labels):\n",
    "        y_pred = self.forward_propagation(data)  # forward pass\n",
    "        one_hot_labels = self.one_hot_matrix(labels)  # convert labels to one-hot\n",
    "        accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(one_hot_labels, axis=1)) * 100 \n",
    "        loss = self.loss.compute_loss(one_hot_labels, y_pred, self.loss_function)  \n",
    "        return loss, accuracy\n",
    "\n",
    "    \n",
    "    def probability(self, data):\n",
    "        return self.forward_propagation(data)  \n",
    "\n",
    "        \n",
    "    def fit(self, batch_size, epochs, optimizer):  \n",
    "        num_samples = self.input.shape[0]  \n",
    "        num_mini_batches = int(np.ceil(num_samples / batch_size))  # total batches  \n",
    "    \n",
    "        for epoch_num in range(epochs):  \n",
    "            step_counter = 1  \n",
    "    \n",
    "            for iteration in range(num_mini_batches):  \n",
    "                start_idx = iteration * batch_size  \n",
    "                end_idx = min(start_idx + batch_size, num_samples)  \n",
    "                batch_images = self.input[start_idx:end_idx]  \n",
    "                batch_labels = self.y_true[start_idx:end_idx]  \n",
    "    \n",
    "                predictions = self.forward_propagation(batch_images)  # forward and backward pass  \n",
    "                true_labels_one_hot = self.one_hot_matrix(batch_labels)  \n",
    "                self.backward_propagation(batch_images, true_labels_one_hot, predictions)  \n",
    "     \n",
    "                for layer_idx in self.grad_weights.keys():  \n",
    "                    self.grad_weights[layer_idx] = self.grad_weights[layer_idx] / batch_size  \n",
    "                    self.grad_biases[layer_idx] = self.grad_biases[layer_idx] / batch_size  \n",
    "      \n",
    "                optimizer.update_parameters(step_counter)  \n",
    "                step_counter = step_counter + 1  \n",
    "    \n",
    "            training_loss, training_acc = self.compute_performance(self.input, self.y_true)  \n",
    "            val_loss, val_acc = self.compute_performance(self.val_img, self.val_true)  \n",
    "    \n",
    "            log_data = {  \n",
    "                'epoch': epoch_num + 1,  \n",
    "                'train_loss': training_loss,  \n",
    "                'train_acc': training_acc,  \n",
    "                'val_loss': val_loss,  \n",
    "                'val_acc': val_acc  \n",
    "            }  \n",
    "    \n",
    "            if self.wan_log:  \n",
    "                wandb.log(log_data)  # log to wandb  \n",
    "    \n",
    "            if self.console_log:  \n",
    "                status_msg = (  \n",
    "                    f\"Epoch {epoch_num + 1}: \"  \n",
    "                    f\"Train Loss={training_loss:.4f}, \"  \n",
    "                    f\"Train Acc={training_acc:.2f}%, \"  \n",
    "                    f\"Val Loss={val_loss:.4f}, \"  \n",
    "                    f\"Val Acc={val_acc:.2f}%\"  \n",
    "                )  \n",
    "                print(status_msg)  \n",
    "    \n",
    "        return training_loss, training_acc, val_loss, val_acc  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d31ba-6077-4621-93f2-2004d7cb1f93",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2596c-56aa-4b0e-a8aa-4ab7ad0b268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimiser: sgd\n",
      "\n",
      "Epoch 1: Train Loss=1.6643, Train Acc=43.83%, Val Loss=1.6599, Val Acc=43.70%\n",
      "Epoch 2: Train Loss=1.3355, Train Acc=53.45%, Val Loss=1.3336, Val Acc=53.43%\n",
      "Epoch 3: Train Loss=1.1828, Train Acc=58.29%, Val Loss=1.1819, Val Acc=58.13%\n",
      "Epoch 4: Train Loss=1.0887, Train Acc=61.30%, Val Loss=1.0886, Val Acc=61.00%\n",
      "Epoch 5: Train Loss=1.0226, Train Acc=63.51%, Val Loss=1.0235, Val Acc=63.17%\n",
      "Test Loss: 1.0571, Test Acc: 61.96%\n",
      "\n",
      "\n",
      "Optimiser: momentum\n",
      "\n",
      "Epoch 1: Train Loss=0.8569, Train Acc=69.80%, Val Loss=0.8717, Val Acc=68.75%\n",
      "Epoch 2: Train Loss=0.7188, Train Acc=74.41%, Val Loss=0.7395, Val Acc=73.35%\n",
      "Epoch 3: Train Loss=0.6562, Train Acc=76.48%, Val Loss=0.6784, Val Acc=75.27%\n",
      "Epoch 4: Train Loss=0.6164, Train Acc=77.90%, Val Loss=0.6398, Val Acc=76.87%\n"
     ]
    }
   ],
   "source": [
    "for opt in [\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\"]:\n",
    "    print(\"Optimiser: \" + opt + \"\\n\")\n",
    "    config_nn = {\n",
    "        \"activation_function\": \"sigmoid\",  \n",
    "        \"init\": \"random\",\n",
    "        \"dataset\": \"fashion_mnist\",\n",
    "        \"loss_function\": \"cross_entropy\", \n",
    "        \"hidden_layers\": 4,\n",
    "        \"hidden_layer_sizes\": 128\n",
    "        \n",
    "    }\n",
    "    \n",
    "    config_opt = {\n",
    "        \"optimizer\": f\"{opt}\",\n",
    "        \"eta\": 0.005,  \n",
    "        \"beta\": 0.9,\n",
    "        \"beta2\": 0.999,\n",
    "        \"beta1\": 0.9,\n",
    "        \"weight_decay\": 0.0005,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"momentum\": 0.9\n",
    "    }\n",
    "    \n",
    "    nn = Neural_Network(config_nn, log=0, console=1)\n",
    "    optimizer = Optimizer(nn, config_opt)\n",
    "    \n",
    "    t_loss, t_acc, v_loss, v_acc = nn.fit(batch_size=64, epochs=5, optimizer=optimizer)\n",
    "    loss, accuracy = nn.compute_performance(nn.test_img, nn.test_true)  # evaluate on test data\n",
    "    print(f\"Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}%\")  # print test loss and accuracy\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab381f1-2f93-4f27-893e-6af71a6b2841",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ce22a-6b99-4f7c-b7cd-bfd0cf9b1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep configuration as specified in question maximizing test accuracy\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  \n",
    "    \"project\": f\"{PROJECT}\",\n",
    "    \"metric\": {\"name\": \"test_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"epochs\": {\"values\": [5, 10]},\n",
    "        \"hidden_layers\": {\"values\": [3, 4, 5]},\n",
    "        \"hidden_layer_sizes\": {\"values\": [32, 64, 128]},\n",
    "        \"weight_decay\": {\"values\": [0, 0.0005, 0.5]},\n",
    "        \"learning_rate\": {\"values\": [1e-3, 1e-4]},\n",
    "        \"optimizer\": {\"values\": [\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\"]},\n",
    "        \"batch_size\": {\"values\": [16, 32, 64]},\n",
    "        \"activation\": {\"values\": [\"sigmoid\", \"tanh\", \"ReLU\"]},\n",
    "        \"initialization\": {\"values\": [\"Xavier\", \"random\"]},\n",
    "        \"dataset\": {\"values\": [\"fashion_mnist\"]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1edd9e-9afe-46e9-ba3a-b7cddf224d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to call inside wandb.agent()\n",
    "def train(loss_function):\n",
    "    sw = wandb.init(project = PROJECT)\n",
    "    sw = sw.config\n",
    "\n",
    "    wandb.run.name = f\"opt_{sw.optimizer}_hl_{sw.hidden_layers}_bs_{sw.batch_size}_e_{sw.epochs}_act_{sw.activation}_eta_{sw.learning_rate}_init_{sw.initialization}_hls_{sw.hidden_layer_sizes}_dataset_{sw.dataset}_{loss_function}\"\n",
    "    # Example: opt_adam_hl_4_bs_32_e_10_act_ReLU_eta_0.001_init_Xavier_hls_64_dataset_fashion_mnist_cross_entropy\n",
    "    \n",
    "    config_nn = {\n",
    "        \"activation_function\": sw.activation, \n",
    "        \"init\" : sw.initialization, \n",
    "        \"dataset\" : sw.dataset,\n",
    "        \"loss_function\" : loss_function,\n",
    "        \"hidden_layers\": sw.hidden_layers,\n",
    "        \"hidden_layer_sizes\" : sw.hidden_layer_sizes\n",
    "    }\n",
    "\n",
    "    config_opt = {\n",
    "        \"optimizer\": sw.optimizer,\n",
    "        \"eta\": sw.learning_rate,\n",
    "        \"beta1\" : 0.9,\n",
    "        \"beta2\" : 0.999,\n",
    "        \"beta\": 0.9,\n",
    "        \"weight_decay\": sw.weight_decay,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"momentum\" : 0.9\n",
    "    }\n",
    "\n",
    "    nn = Neural_Network(config_nn,log = 1,console=1)\n",
    "    opt = Optimizer(nn, config_opt)\n",
    "\n",
    "    t_loss, t_acc, v_loss, v_acc = nn.fit(batch_size=sw.batch_size, epochs=sw.epochs, optimizer=opt)\n",
    "\n",
    "    loss, accuracy = nn.compute_performance(nn.test_img, nn.test_true)  # evaluate on test data\n",
    "    print(f\"Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}%\")  # print test loss and accuracy\n",
    "    wandb.log({\"test_accuracy\" : accuracy})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d1f11-1b39-4a3c-afd9-d007b97c9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)\n",
    "wandb.agent(sweep_id,  lambda : train(loss_function = \"cross_entropy\"), count = SWEEPCOUNT)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a3356-1ee8-4484-bc10-274c21ae29f8",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Plot can be seen [here](https://wandb.ai/cs24m021-iit-madras/DA6401_DL_Assignment1/reports/DA6401-Assignment-1--VmlldzoxMTc4Mzg1Mw)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21d5dd-c2c8-41d0-8049-ee57d478c50e",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Plot can be seen [here](https://wandb.ai/cs24m021-iit-madras/DA6401_DL_Assignment1/reports/DA6401-Assignment-1--VmlldzoxMTc4Mzg1Mw)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a06e4-9df6-42fa-9d83-d6798680fa06",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f638aa2-1fc9-4900-95df-98f45183f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot_confusion_matrix(y_pred, y_true):  \n",
    "    \n",
    "    wandb.init(project=PROJECT, name=\"Question:7\")  \n",
    "    \n",
    "    predicted_classes = np.argmax(y_pred, axis=1)   # predicted classes \n",
    "    num_labels = len(target_classes)  \n",
    "    conf_matrix = np.zeros((num_labels, num_labels), dtype=int)  \n",
    "      \n",
    "    for idx, actual_label in enumerate(y_true):  \n",
    "        true_idx = int(actual_label)  \n",
    "        pred_idx = int(predicted_classes[idx])  \n",
    "        \n",
    "        if (true_idx >= 0 and true_idx < num_labels) and (pred_idx >= 0 and pred_idx < num_labels):  \n",
    "            conf_matrix[true_idx, pred_idx] += 1  \n",
    "        else:  \n",
    "            print(f\"Skipping invalid index: y_true={true_idx}, y_pred={pred_idx}\")  \n",
    "    \n",
    "    df_confusion = pd.DataFrame(conf_matrix, index=target_classes, columns=target_classes)  \n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 15))  # plot heatmap  \n",
    "    ax = sns.heatmap(  \n",
    "        df_confusion,  \n",
    "        annot=True,  \n",
    "        fmt='d',  \n",
    "        cmap=\"Reds\",  \n",
    "        linewidths=4,  \n",
    "        linecolor='white'  \n",
    "    )  \n",
    "    ax.set_xlabel(\"Predicted Class\")  \n",
    "    ax.set_ylabel(\"True Class\")  \n",
    "    ax.set_xticklabels(target_classes, rotation=90)  \n",
    "    ax.set_yticklabels(target_classes, rotation=0)  \n",
    "    plt.title('Confusion Matrix', fontsize=12)  \n",
    "    \n",
    "    plt.show()  \n",
    "    wandb.log({\"conf_mat\": wandb.plot.confusion_matrix(probs=None,\n",
    "                                                       y_true=y_true, \n",
    "                                                       preds=predicted_classes,\n",
    "                                                       class_names=target_classes)})  \n",
    "    wandb.finish()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c792e6-cdfb-48c0-ab9c-d28e90aee3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best config was opt_rmsprop_hl_4_bs_16_e_10_act_ReLU_eta_0.0001_init_Xavier_hls_128_dataset_fashion_mnist_cross_entropy\n",
    "config_nn = {\n",
    "        \"activation_function\": \"ReLU\",  \n",
    "        \"init\": \"Xavier\",\n",
    "        \"dataset\": \"fashion_mnist\",\n",
    "        \"loss_function\": \"cross_entropy\", \n",
    "        \"hidden_layers\": 4,\n",
    "        \"hidden_layer_sizes\": 128\n",
    "        \n",
    "}\n",
    "\n",
    "config_opt = {\n",
    "    \"optimizer\": \"rmsprop\",\n",
    "    \"eta\": 0.0001,  \n",
    "    \"beta\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"beta1\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"momentum\": 0.9\n",
    "}\n",
    "\n",
    "nn = Neural_Network(config_nn, log=0, console=1)\n",
    "optimizer = Optimizer(nn, config_opt)\n",
    "\n",
    "t_loss, t_acc, v_loss, v_acc = nn.fit(batch_size=16, epochs=10, optimizer=optimizer)\n",
    "loss, accuracy = nn.compute_performance(nn.test_img, nn.test_true)  # evaluate on test data\n",
    "print(f\"Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}%\")  # print test loss and accuracy\n",
    "y_pred = nn.probability(nn.test_img)\n",
    "generate_and_plot_confusion_matrix(y_pred, nn.test_true) # plot confusion matrox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83730bb-ddb5-4242-9b88-e34e7a3460a2",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d146cd0-03a5-41ba-b2ac-7438b3ea56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)\n",
    "wandb.agent(sweep_id,  lambda : train(loss_function = \"mean_squared_error\"), count = 150)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765c217-0265-4500-8d7b-afc752aef8fa",
   "metadata": {},
   "source": [
    "## Question 9 \n",
    " \n",
    "- [GitHub Repository](https://github.com/karan757527/DA6401)  \n",
    "- [Project Report](https://wandb.ai/cs24m021-iit-madras/DA6401_DL_Assignment1/reports/DA6401-Assignment-1--VmlldzoxMTc4Mzg1Mw)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03967f39-c42b-4996-8773-7fbaa24a466a",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799dd799-4ab5-4fa7-870f-8cebc2e14ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best three configurations are:\n",
    "config_nn = [{\n",
    "        \"activation_function\": \"ReLU\",  \n",
    "        \"init\": \"Xavier\",\n",
    "        \"dataset\": \"mnist\",\n",
    "        \"loss_function\": \"cross_entropy\", \n",
    "        \"hidden_layers\": 4,\n",
    "        \"hidden_layer_sizes\": 128\n",
    "        \n",
    "},\n",
    "            {\n",
    "        \"activation_function\": \"ReLU\",  \n",
    "        \"init\": \"Xavier\",\n",
    "        \"dataset\": \"mnist\",\n",
    "        \"loss_function\": \"cross_entropy\", \n",
    "        \"hidden_layers\": 3,\n",
    "        \"hidden_layer_sizes\": 128\n",
    "        \n",
    "},\n",
    "            {\n",
    "        \"activation_function\": \"tanh\",  \n",
    "        \"init\": \"Xavier\",\n",
    "        \"dataset\": \"mnist\",\n",
    "        \"loss_function\": \"cross_entropy\", \n",
    "        \"hidden_layers\": 3,\n",
    "        \"hidden_layer_sizes\": 64\n",
    "        \n",
    "}]\n",
    "\n",
    "config_opt = [{\n",
    "    \"optimizer\": \"rmsprop\",\n",
    "    \"eta\": 0.0001,  \n",
    "    \"beta\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"beta1\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"momentum\": 0.9\n",
    "},\n",
    "              {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"eta\": 0.001,  \n",
    "    \"beta\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"beta1\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"momentum\": 0.9\n",
    "},\n",
    "              {\n",
    "    \"optimizer\": \"momentum\",\n",
    "    \"eta\": 0.01,  \n",
    "    \"beta\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"beta1\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"momentum\": 0.9\n",
    "}]\n",
    "\n",
    "batch_size=[16, 32, 32]\n",
    "\n",
    "for i in range(3):  # Loop through all three configurations\n",
    "    print(f\"Running configuration {i+1}...\")\n",
    "    \n",
    "    nn = Neural_Network(config_nn[i], log=0, console=1)\n",
    "    optimizer = Optimizer(nn, config_opt[i])\n",
    "    \n",
    "    t_loss, t_acc, v_loss, v_acc = nn.fit(batch_size=batch_size[i], epochs=10, optimizer=optimizer)\n",
    "    loss, accuracy = nn.compute_performance(nn.test_img, nn.test_true)  # Evaluate on test data\n",
    "    \n",
    "    print(f\"Config {i+1} - Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01218e-99d0-4ac9-a98d-ae20ba36e264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e24443-7277-45f9-b977-cf67635a9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -wp DA6401A1 -e 15 -b 64 -o adam -lr 0.001 -beta1 0.999 -beta2 0.9 -w_i Xavier -nhl 4  -sz 128 -a sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8e323-5113-430d-b459-71c707c80bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
